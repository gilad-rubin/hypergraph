{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraph import Graph, node\n",
    "from hypergraph.viz import visualize\n",
    "\n",
    "\n",
    "@node(output_name=\"raw_documents\")\n",
    "def fetch_documents(query, search_term) -> list:\n",
    "    return []\n",
    "\n",
    "\n",
    "@node(output_name=\"raw_images\")\n",
    "def fetch_images(doc_ids, search_term: str, query) -> list:\n",
    "    return []\n",
    "\n",
    "\n",
    "@node(output_name=\"raw_metadata\")\n",
    "def fetch_metadata(api_key: str, doc_ids: list) -> dict:\n",
    "    return {}\n",
    "\n",
    "\n",
    "@node(output_name=(\"combined_data\"))\n",
    "def combine(raw_metadata, raw_images):\n",
    "    return []\n",
    "\n",
    "\n",
    "graph = Graph(\n",
    "    nodes=[fetch_documents, fetch_images, fetch_metadata, combine],\n",
    "    name=\"data_ingestion\",\n",
    ")\n",
    "\n",
    "visualize(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraph import Graph, node\n",
    "from hypergraph.nodes.gate import ifelse\n",
    "\n",
    "\n",
    "# Two mutex branches, both produce \"result\"\n",
    "@ifelse(when_true=\"fast_path\", when_false=\"slow_path\")\n",
    "def choose_path(x: int) -> bool:\n",
    "    return x >= 0\n",
    "\n",
    "\n",
    "@node(output_name=\"result\")\n",
    "def fast_path(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "@node(output_name=\"result\")\n",
    "def slow_path(x: int) -> int:\n",
    "    return x - 1\n",
    "\n",
    "\n",
    "@node(output_name=\"summary\")\n",
    "def summarize(result: int) -> int:\n",
    "    return result * 10\n",
    "\n",
    "\n",
    "g = Graph([choose_path, fast_path, slow_path, summarize], name=\"mutex_outputs\")\n",
    "\n",
    "# Visualize (try both modes)\n",
    "g.visualize(depth=0, separate_outputs=False)  # classic, primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.visualize(depth=0, separate_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraph import Graph, node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"y\")\n",
    "def double(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "@node(output_name=\"z\")\n",
    "def square(y: int) -> int:\n",
    "    return y**2\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# RAG pipeline\n",
    "# ===============================\n",
    "@node(output_name=\"embedding\")\n",
    "def embed(text: str) -> list[float]:\n",
    "    return [0.1] * 10\n",
    "\n",
    "\n",
    "@node(output_name=\"docs\")\n",
    "def retrieve(embedding: list[float]) -> list[str]:\n",
    "    return [\"doc1\", \"doc2\"]\n",
    "\n",
    "\n",
    "@node(output_name=\"answer\")\n",
    "def generate(docs: list[str], query: str) -> str:\n",
    "    return \"Answer\"\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Diamond pattern\n",
    "# ===============================\n",
    "@node(output_name=\"a\")\n",
    "def start(x: int) -> int:\n",
    "    return x\n",
    "\n",
    "\n",
    "@node(output_name=\"b\")\n",
    "def left(a: int) -> int:\n",
    "    return a + 1\n",
    "\n",
    "\n",
    "@node(output_name=\"c\")\n",
    "def right(a: int) -> int:\n",
    "    return a * 2\n",
    "\n",
    "\n",
    "@node(output_name=\"d\")\n",
    "def merge(b: int, c: int) -> int:\n",
    "    return b + c\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Complex RAG (19 nodes)\n",
    "# ===============================\n",
    "@node(output_name=\"raw_text\")\n",
    "def load_data(filepath: str) -> str:\n",
    "    return \"raw content\"\n",
    "\n",
    "\n",
    "@node(output_name=\"cleaned_text\")\n",
    "def clean(raw_text: str) -> str:\n",
    "    return raw_text.strip()\n",
    "\n",
    "\n",
    "@node(output_name=\"tokens\")\n",
    "def tokenize(cleaned_text: str) -> list[str]:\n",
    "    return cleaned_text.split()\n",
    "\n",
    "\n",
    "@node(output_name=\"chunks\")\n",
    "def chunk(tokens: list[str], chunk_size: int) -> list[list[str]]:\n",
    "    return [tokens[i : i + chunk_size] for i in range(0, len(tokens), chunk_size)]\n",
    "\n",
    "\n",
    "@node(output_name=\"embeddings\")\n",
    "def embed_chunks(chunks: list[list[str]], model_name: str) -> list[list[float]]:\n",
    "    return [[0.1] * 768 for _ in chunks]\n",
    "\n",
    "\n",
    "@node(output_name=\"normalized_embeddings\")\n",
    "def normalize(embeddings: list[list[float]]) -> list[list[float]]:\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "@node(output_name=\"index\")\n",
    "def build_index(normalized_embeddings: list[list[float]]) -> dict:\n",
    "    return {\"vectors\": normalized_embeddings}\n",
    "\n",
    "\n",
    "@node(output_name=\"query_text\")\n",
    "def parse_query(user_input: str) -> str:\n",
    "    return user_input.strip()\n",
    "\n",
    "\n",
    "@node(output_name=\"query_embedding\")\n",
    "def embed_query(query_text: str, model_name: str) -> list[float]:\n",
    "    return [0.1] * 768\n",
    "\n",
    "\n",
    "@node(output_name=\"expanded_queries\")\n",
    "def expand_query(query_text: str) -> list[str]:\n",
    "    return [query_text, f\"{query_text} synonym\"]\n",
    "\n",
    "\n",
    "@node(output_name=\"query_embeddings\")\n",
    "def embed_expanded(expanded_queries: list[str], model_name: str) -> list[list[float]]:\n",
    "    return [[0.1] * 768 for _ in expanded_queries]\n",
    "\n",
    "\n",
    "@node(output_name=\"candidates\")\n",
    "def search_index(index: dict, query_embedding: list[float], top_k: int) -> list[int]:\n",
    "    return list(range(top_k))\n",
    "\n",
    "\n",
    "@node(output_name=\"expanded_candidates\")\n",
    "def search_expanded(index: dict, query_embeddings: list[list[float]], top_k: int) -> list[int]:\n",
    "    return list(range(top_k * 2))\n",
    "\n",
    "\n",
    "@node(output_name=\"merged_candidates\")\n",
    "def merge_results(candidates: list[int], expanded_candidates: list[int]) -> list[int]:\n",
    "    return list(set(candidates + expanded_candidates))\n",
    "\n",
    "\n",
    "@node(output_name=\"retrieved_docs\")\n",
    "def fetch_documents(merged_candidates: list[int], chunks: list[list[str]]) -> list[str]:\n",
    "    return [\" \".join(chunks[i]) for i in merged_candidates if i < len(chunks)]\n",
    "\n",
    "\n",
    "@node(output_name=\"context\")\n",
    "def format_context(retrieved_docs: list[str]) -> str:\n",
    "    return \"\\n\\n\".join(retrieved_docs)\n",
    "\n",
    "\n",
    "@node(output_name=\"prompt\")\n",
    "def build_prompt(context: str, query_text: str, system_prompt: str) -> str:\n",
    "    return f\"{system_prompt}\\n\\nContext:\\n{context}\\n\\nQuery: {query_text}\"\n",
    "\n",
    "\n",
    "@node(output_name=\"raw_response\")\n",
    "def call_llm(prompt: str, temperature: float, max_tokens: int) -> str:\n",
    "    return \"Generated response...\"\n",
    "\n",
    "\n",
    "@node(output_name=\"final_answer\")\n",
    "def postprocess(raw_response: str) -> str:\n",
    "    return raw_response.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_rag = Graph(\n",
    "    nodes=[\n",
    "        chunk,\n",
    "        load_data,\n",
    "        clean,\n",
    "        tokenize,\n",
    "        embed_chunks,\n",
    "        normalize,\n",
    "        build_index,\n",
    "        parse_query,\n",
    "        embed_query,\n",
    "        expand_query,\n",
    "        embed_expanded,\n",
    "        search_index,\n",
    "        search_expanded,\n",
    "        merge_results,\n",
    "        fetch_documents,\n",
    "        format_context,\n",
    "        build_prompt,\n",
    "        call_llm,\n",
    "        postprocess,\n",
    "    ],\n",
    "    name=\"rag_pipeline\",\n",
    ")\n",
    "complex_rag.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraph.viz import extract_debug_data\n",
    "\n",
    "data = extract_debug_data(complex_rag, depth=0)\n",
    "\n",
    "# Show unique heights\n",
    "heights = set(n[\"height\"] for n in data.nodes)\n",
    "print(f\"Unique heights: {sorted(heights)}\")\n",
    "\n",
    "# Show nodes with their heights\n",
    "for n in sorted(data.nodes, key=lambda x: x[\"height\"], reverse=True)[:10]:\n",
    "    print(f\"  {n['id']}: {n['height']}px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraph import ifelse\n",
    "\n",
    "\n",
    "@node(output_name=\"cached_result\")\n",
    "def use_cache(query: str) -> str:\n",
    "    \"\"\"Return cached result.\"\"\"\n",
    "    return \"cached answer\"\n",
    "\n",
    "\n",
    "@node(output_name=\"fresh_result\")\n",
    "def compute_fresh(query: str) -> str:\n",
    "    \"\"\"Compute fresh result.\"\"\"\n",
    "    return \"fresh answer\"\n",
    "\n",
    "\n",
    "@ifelse(when_true=\"use_cache\", when_false=\"compute_fresh\")\n",
    "def check_cache(query: str) -> bool:\n",
    "    \"\"\"Check if query is in cache.\"\"\"\n",
    "    return query in [\"hello\", \"world\"]\n",
    "\n",
    "\n",
    "branching = Graph(nodes=[check_cache, use_cache, compute_fresh])\n",
    "branching.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = extract_debug_data(branching, depth=0)\n",
    "heights = set(n[\"height\"] for n in data.nodes)\n",
    "print(f\"Unique heights: {sorted(heights)}\")\n",
    "for n in data.nodes:\n",
    "    print(f\"  {n['id']}: {n['height']}px, type={n.get('nodeType', '?')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraph import route\n",
    "\n",
    "\n",
    "@node(output_name=\"small_result\")\n",
    "def process_small(data: str) -> str:\n",
    "    return \"processed small\"\n",
    "\n",
    "\n",
    "@node(output_name=\"medium_result\")\n",
    "def process_medium() -> str:\n",
    "    return \"processed medium\"\n",
    "\n",
    "\n",
    "@node(output_name=\"large_result\")\n",
    "def process_large(data: str) -> str:\n",
    "    return \"processed large\"\n",
    "\n",
    "\n",
    "@route(targets=[\"process_small\", \"process_medium\", \"process_large\"])\n",
    "def classify_size(data: str) -> str:\n",
    "    \"\"\"Classify data by size.\"\"\"\n",
    "    if len(data) < 10:\n",
    "        return \"process_small\"\n",
    "    elif len(data) < 100:\n",
    "        return \"process_medium\"\n",
    "    return \"process_large\"\n",
    "\n",
    "\n",
    "routing = Graph(nodes=[classify_size, process_small, process_medium, process_large])\n",
    "routing.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 9. Nested Graph (Hierarchical Composition)\n",
    "\n",
    "Graphs can contain other graphs as nodes. Use `depth` to control expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner graph: text processing pipeline\n",
    "@node(output_name=\"cleaned\")\n",
    "def clean_text(text: str) -> str:\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "@node(output_name=\"normalized\")\n",
    "def normalize(cleaned: str) -> str:\n",
    "    return cleaned.lower()\n",
    "\n",
    "\n",
    "preprocess = Graph(nodes=[clean_text, normalize], name=\"preprocess\")\n",
    "\n",
    "\n",
    "# Outer graph using the inner graph\n",
    "@node(output_name=\"result\")\n",
    "def analyze(normalized: str) -> dict:\n",
    "    return {\"length\": len(normalized)}\n",
    "\n",
    "\n",
    "workflow = Graph(nodes=[preprocess.as_node(), analyze])\n",
    "print(\"depth=0 (collapsed):\")\n",
    "workflow.visualize(depth=2, separate_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraph.viz import extract_debug_data\n",
    "\n",
    "# Extract rendered debug data via Playwright\n",
    "data = extract_debug_data(workflow, depth=1)\n",
    "\n",
    "# Print report\n",
    "data.print_report()\n",
    "\n",
    "# Access edge issues programmatically\n",
    "for edge in data.edge_issues:\n",
    "    print(f\"{edge.source} -> {edge.target}: {edge.issue}\")\n",
    "    print(f\"  srcBottom={edge.src_bottom}, tgtTop={edge.tgt_top}\")\n",
    "    print(f\"  vertDist={edge.vert_dist}, horizDist={edge.horiz_dist}\")\n",
    "\n",
    "# Access all data\n",
    "print(f\"Nodes: {len(data.nodes)}\")\n",
    "print(f\"Edges: {len(data.edges)}\")\n",
    "print(f\"Issues: {data.summary['edgeIssues']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraph.viz import visualize\n",
    "\n",
    "# In Jupyter notebook - shows with debug overlay tabs\n",
    "visualize(workflow, depth=0, _debug_overlays=False, separate_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 1: Simple transform\n",
    "@node(output_name=\"step1_out\")\n",
    "def step1(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "@node(output_name=\"step2_out\")\n",
    "def step2(step1_out: int) -> int:\n",
    "    return step1_out * 2\n",
    "\n",
    "\n",
    "inner = Graph(nodes=[step1, step2], name=\"inner\")\n",
    "\n",
    "\n",
    "# Level 2: Wrap inner + add validation\n",
    "@node(output_name=\"validated\")\n",
    "def validate(step2_out: int) -> int:\n",
    "    return step2_out\n",
    "\n",
    "\n",
    "middle = Graph(nodes=[inner.as_node(), validate], name=\"middle\")\n",
    "\n",
    "\n",
    "# Level 3: Wrap middle + add logging\n",
    "@node(output_name=\"logged\")\n",
    "def log_result(validated: int) -> int:\n",
    "    print(f\"Result: {validated}\")\n",
    "    return validated\n",
    "\n",
    "\n",
    "outer = Graph(nodes=[middle.as_node(), log_result])\n",
    "\n",
    "print(\"depth=0:\")\n",
    "outer.visualize(depth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"depth=1:\")\n",
    "outer.visualize(depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"depth=2 (fully expanded):\")\n",
    "outer.visualize(depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = Graph(nodes=[embed, retrieve, generate])\n",
    "rag.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond = Graph(nodes=[start, left, right, merge])\n",
    "diamond.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Simple 2-Node Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"y\")\n",
    "def double(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "@node(output_name=\"z\")\n",
    "def square(y: int) -> int:\n",
    "    return y**2\n",
    "\n",
    "\n",
    "graph = Graph(nodes=[double, square])\n",
    "graph.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## RAG Pipeline (3 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"embedding\")\n",
    "def embed(text: str) -> list[float]:\n",
    "    return [0.1] * 10\n",
    "\n",
    "\n",
    "@node(output_name=\"docs\")\n",
    "def retrieve(embedding: list[float]) -> list[str]:\n",
    "    return [\"doc1\", \"doc2\"]\n",
    "\n",
    "\n",
    "@node(output_name=\"answer\")\n",
    "def generate(docs: list[str], query: str) -> str:\n",
    "    return \"Answer\"\n",
    "\n",
    "\n",
    "rag = Graph(nodes=[embed, retrieve, generate])\n",
    "rag.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"embedding\")\n",
    "def embed() -> list[float]:\n",
    "    return [0.1] * 10\n",
    "\n",
    "\n",
    "rag = Graph(nodes=[embed])\n",
    "rag.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## With Type Hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag.visualize(show_types=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Wider Graph (Diamond Pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"a\")\n",
    "def start(x: int) -> int:\n",
    "    return x\n",
    "\n",
    "\n",
    "@node(output_name=\"b\")\n",
    "def left(a: int) -> int:\n",
    "    return a + 1\n",
    "\n",
    "\n",
    "@node(output_name=\"c\")\n",
    "def right(a: int) -> int:\n",
    "    return a * 2\n",
    "\n",
    "\n",
    "@node(output_name=\"d\")\n",
    "def merge(b: int, c: int) -> int:\n",
    "    return b + c\n",
    "\n",
    "\n",
    "diamond = Graph(nodes=[start, left, right, merge])\n",
    "diamond.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Light Theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond.visualize(theme=\"light\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
