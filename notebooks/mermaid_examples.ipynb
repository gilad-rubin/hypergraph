{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Mermaid Diagram Examples\n\nTest `graph.to_mermaid()` rendering — fully offline, no data sent externally.\n\n- **JupyterLab 4.1+**: uses native `text/vnd.mermaid` MIME type\n- **VSCode / older Jupyter**: uses bundled `beautiful-mermaid` JS (rendered locally in iframe)\n- **`print()`**: raw Mermaid text you can paste anywhere"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraph import Graph, node, route, ifelse, END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flowchart TD\n",
       "    %% Inputs\n",
       "    input_raw_text([\"raw_text\"])\n",
       "    %% Nodes\n",
       "    clean[\"clean\"]\n",
       "    tokenize[\"tokenize\"]\n",
       "    embed[\"embed\"]\n",
       "    %% Edges\n",
       "    input_raw_text --> clean\n",
       "    clean -->|cleaned| tokenize\n",
       "    tokenize -->|tokens| embed\n",
       "\n",
       "    %% Styling\n",
       "    classDef function fill:#E8EAF6,stroke:#5C6BC0,stroke-width:2px,color:#283593\n",
       "    classDef input fill:#E0F7FA,stroke:#0097A7,stroke-width:2px,color:#004D40\n",
       "    class clean,tokenize,embed function\n",
       "    class input_raw_text input"
      ],
      "text/vnd.mermaid": [
       "flowchart TD\n",
       "    %% Inputs\n",
       "    input_raw_text([\"raw_text\"])\n",
       "    %% Nodes\n",
       "    clean[\"clean\"]\n",
       "    tokenize[\"tokenize\"]\n",
       "    embed[\"embed\"]\n",
       "    %% Edges\n",
       "    input_raw_text --> clean\n",
       "    clean -->|cleaned| tokenize\n",
       "    tokenize -->|tokens| embed\n",
       "\n",
       "    %% Styling\n",
       "    classDef function fill:#E8EAF6,stroke:#5C6BC0,stroke-width:2px,color:#283593\n",
       "    classDef input fill:#E0F7FA,stroke:#0097A7,stroke-width:2px,color:#004D40\n",
       "    class clean,tokenize,embed function\n",
       "    class input_raw_text input"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@node(output_name=\"cleaned\")\n",
    "def clean(raw_text: str) -> str:\n",
    "    return raw_text.strip().lower()\n",
    "\n",
    "\n",
    "@node(output_name=\"tokens\")\n",
    "def tokenize(cleaned: str) -> list[str]:\n",
    "    return cleaned.split()\n",
    "\n",
    "\n",
    "@node(output_name=\"embedding\")\n",
    "def embed(tokens: list[str]) -> list[float]:\n",
    "    return [0.1] * len(tokens)\n",
    "\n",
    "\n",
    "pipeline = Graph(nodes=[clean, tokenize, embed])\n",
    "pipeline.to_mermaid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. With Type Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.to_mermaid(show_types=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Branching (ifelse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"cached_result\")\n",
    "def use_cache(query: str) -> str:\n",
    "    return \"cached answer\"\n",
    "\n",
    "\n",
    "@node(output_name=\"fresh_result\")\n",
    "def compute_fresh(query: str) -> str:\n",
    "    return \"fresh answer\"\n",
    "\n",
    "\n",
    "@ifelse(when_true=\"use_cache\", when_false=\"compute_fresh\")\n",
    "def check_cache(query: str) -> bool:\n",
    "    return query in [\"hello\", \"world\"]\n",
    "\n",
    "\n",
    "Graph(nodes=[check_cache, use_cache, compute_fresh]).to_mermaid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agentic Loop (cycle with END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"response\")\n",
    "def generate(messages: list[dict]) -> str:\n",
    "    return \"I can help with that!\"\n",
    "\n",
    "\n",
    "@node(output_name=\"messages\")\n",
    "def accumulate(messages: list[dict], response: str) -> list[dict]:\n",
    "    return messages + [{\"role\": \"assistant\", \"content\": response}]\n",
    "\n",
    "\n",
    "@route(targets=[\"generate\", END])\n",
    "def should_continue(messages: list[dict]) -> str:\n",
    "    if len(messages) > 5:\n",
    "        return END\n",
    "    return \"generate\"\n",
    "\n",
    "\n",
    "Graph(nodes=[generate, accumulate, should_continue]).to_mermaid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Nested Graph (collapsed vs expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"cleaned\")\n",
    "def clean_text(text: str) -> str:\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "@node(output_name=\"normalized\")\n",
    "def normalize(cleaned: str) -> str:\n",
    "    return cleaned.lower()\n",
    "\n",
    "\n",
    "preprocess = Graph(nodes=[clean_text, normalize], name=\"preprocess\")\n",
    "\n",
    "\n",
    "@node(output_name=\"result\")\n",
    "def analyze(normalized: str) -> dict:\n",
    "    return {\"length\": len(normalized)}\n",
    "\n",
    "\n",
    "workflow = Graph(nodes=[preprocess.as_node(), analyze])\n",
    "workflow.to_mermaid(depth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.to_mermaid(depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Direction and Separate Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.to_mermaid(direction=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.to_mermaid(separate_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Raw Source\n",
    "\n",
    "`print()` gives you the raw Mermaid text — paste into any Mermaid-compatible tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline.to_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Force HTML Fallback (beautiful-mermaid)\n\nExplicitly test the `_repr_html_` path — this is what VSCode and older notebooks use.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from IPython.display import HTML, display\n\ndiagram = pipeline.to_mermaid()\ndisplay(HTML(diagram._repr_html_()))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}