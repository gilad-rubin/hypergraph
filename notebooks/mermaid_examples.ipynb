{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mermaid Diagram Examples\n",
    "\n",
    "Test `graph.to_mermaid()` rendering. Uses the native `text/vnd.mermaid` MIME type — no CDN, no external services. Requires JupyterLab 4.1+ or Notebook 7.1+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraph import Graph, node, route, ifelse, END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"cleaned\")\n",
    "def clean(raw_text: str) -> str:\n",
    "    return raw_text.strip().lower()\n",
    "\n",
    "\n",
    "@node(output_name=\"tokens\")\n",
    "def tokenize(cleaned: str) -> list[str]:\n",
    "    return cleaned.split()\n",
    "\n",
    "\n",
    "@node(output_name=\"embedding\")\n",
    "def embed(tokens: list[str]) -> list[float]:\n",
    "    return [0.1] * len(tokens)\n",
    "\n",
    "\n",
    "pipeline = Graph(nodes=[clean, tokenize, embed])\n",
    "pipeline.to_mermaid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. With Type Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.to_mermaid(show_types=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Branching (ifelse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"cached_result\")\n",
    "def use_cache(query: str) -> str:\n",
    "    return \"cached answer\"\n",
    "\n",
    "\n",
    "@node(output_name=\"fresh_result\")\n",
    "def compute_fresh(query: str) -> str:\n",
    "    return \"fresh answer\"\n",
    "\n",
    "\n",
    "@ifelse(when_true=\"use_cache\", when_false=\"compute_fresh\")\n",
    "def check_cache(query: str) -> bool:\n",
    "    return query in [\"hello\", \"world\"]\n",
    "\n",
    "\n",
    "Graph(nodes=[check_cache, use_cache, compute_fresh]).to_mermaid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agentic Loop (cycle with END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"response\")\n",
    "def generate(messages: list[dict]) -> str:\n",
    "    return \"I can help with that!\"\n",
    "\n",
    "\n",
    "@node(output_name=\"messages\")\n",
    "def accumulate(messages: list[dict], response: str) -> list[dict]:\n",
    "    return messages + [{\"role\": \"assistant\", \"content\": response}]\n",
    "\n",
    "\n",
    "@route(targets=[\"generate\", END])\n",
    "def should_continue(messages: list[dict]) -> str:\n",
    "    if len(messages) > 5:\n",
    "        return END\n",
    "    return \"generate\"\n",
    "\n",
    "\n",
    "Graph(nodes=[generate, accumulate, should_continue]).to_mermaid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Nested Graph (collapsed vs expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"cleaned\")\n",
    "def clean_text(text: str) -> str:\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "@node(output_name=\"normalized\")\n",
    "def normalize(cleaned: str) -> str:\n",
    "    return cleaned.lower()\n",
    "\n",
    "\n",
    "preprocess = Graph(nodes=[clean_text, normalize], name=\"preprocess\")\n",
    "\n",
    "\n",
    "@node(output_name=\"result\")\n",
    "def analyze(normalized: str) -> dict:\n",
    "    return {\"length\": len(normalized)}\n",
    "\n",
    "\n",
    "workflow = Graph(nodes=[preprocess.as_node(), analyze])\n",
    "workflow.to_mermaid(depth=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.to_mermaid(depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Direction and Separate Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.to_mermaid(direction=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.to_mermaid(separate_outputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Raw Source\n",
    "\n",
    "`print()` gives you the raw Mermaid text — paste into any Mermaid-compatible tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline.to_mermaid())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
