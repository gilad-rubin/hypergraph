{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# `.log` — Universal Drill-Down\n",
    "\n",
    "One accessor at every level. The chain is always `.log.steps[i].log.steps[j]...`\n",
    "\n",
    "| Object | `.log` returns | Type |\n",
    "|--------|---------------|------|\n",
    "| `RunResult` | trace of this run | `RunLog` |\n",
    "| `MapResult` | batch overview | `MapLog` |\n",
    "| `NodeRecord` (leaf) | — | `None` |\n",
    "| `NodeRecord` (1 inner) | inner trace | `RunLog` |\n",
    "| `NodeRecord` (N inner) | batch of inner traces | `MapLog` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergraph import SyncRunner, Graph, node, ifelse, END\n",
    "\n",
    "\n",
    "@node(output_name=\"doubled\")\n",
    "def double(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "@node(output_name=\"tripled\")\n",
    "def triple(doubled: int) -> int:\n",
    "    return doubled * 3\n",
    "\n",
    "\n",
    "runner = SyncRunner()\n",
    "graph = Graph([double, triple], name=\"pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Single run → `RunLog`\n",
    "\n",
    "`result.log` — just type it, the table shows automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = runner.run(graph, {\"x\": 5})\n",
    "result.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.log.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.log.timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.log.node_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Leaf nodes have `.log = None` — nothing nested:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.log.steps[0].log is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 2. Mapped run → `MapLog`\n",
    "\n",
    "`results.log` gives you a `MapLog` — batch overview with per-item drill-down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = runner.map(graph, {\"x\": [1, 2, 3, 4, 5]}, map_over=\"x\")\n",
    "results.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.log.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Drill into one item — **same `RunLog` as Step 1**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.log[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate stats across ALL items (cross-item bottleneck analysis)\n",
    "results.log.node_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 3. Nested graph → `.log` on steps\n",
    "\n",
    "When a graph runs as a node inside another graph, `step.log` reveals the inner trace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = Graph([double, triple], name=\"pipeline\")\n",
    "outer = Graph([inner.as_node()])\n",
    "result = runner.run(outer, {\"x\": 5})\n",
    "result.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The footer tells you where to drill. Single nested → `step.log` is a `RunLog`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.log.steps[0].log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### map_over → `step.log` is a `MapLog`\n",
    "\n",
    "When the inner graph runs N times, `step.log` returns a `MapLog` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_mapped = Graph([inner.as_node().map_over(\"x\")])\n",
    "result = runner.run(outer_mapped, {\"x\": [1, 2, 3, 4, 5]})\n",
    "result.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = result.log.steps[0]\n",
    "step.log  # MapLog — same as results.log in Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "step.log[0]  # drill into first item → RunLog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 4. Deep nesting — the chain keeps going\n",
    "\n",
    "Three levels deep: outer → middle → innermost. The `.log` chain works at every level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"incremented\")\n",
    "def increment(doubled: int) -> int:\n",
    "    return doubled + 1\n",
    "\n",
    "\n",
    "innermost = Graph([double], name=\"innermost\")\n",
    "middle = Graph([innermost.as_node(), increment], name=\"middle\")\n",
    "outer = Graph([middle.as_node()])\n",
    "\n",
    "result = runner.run(outer, {\"x\": 5})\n",
    "result.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer → middle (RunLog)\n",
    "middle_log = result.log.steps[0].log\n",
    "middle_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# middle → innermost (RunLog)\n",
    "innermost_step = next(s for s in middle_log.steps if s.node_name == \"innermost\")\n",
    "innermost_step.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## 5. Errors — find failures across items\n",
    "\n",
    "`MapLog.errors` aggregates all failed `NodeRecord`s across all items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node(output_name=\"result\")\n",
    "def maybe_fail(x: int) -> int:\n",
    "    if x % 2 == 0:\n",
    "        raise ValueError(f\"even: {x}\")\n",
    "    return x * 10\n",
    "\n",
    "\n",
    "fail_graph = Graph([maybe_fail], name=\"checker\")\n",
    "results = runner.map(fail_graph, {\"x\": [1, 2, 3, 4, 5]}, map_over=\"x\", error_handling=\"continue\")\n",
    "results.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.log.errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which items failed?\n",
    "[(i, log.errors[0].error) for i, log in enumerate(results.log) if log.errors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## 6. Serialization\n",
    "\n",
    "Both `RunLog` and `MapLog` serialize to JSON via `.to_dict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "result = runner.run(graph, {\"x\": 5})\n",
    "print(json.dumps(result.log.to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = runner.map(graph, {\"x\": [1, 2]}, map_over=\"x\")\n",
    "print(json.dumps(results.log.to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## 7. CLI — Inspect Runs from the Terminal\n",
    "\n",
    "Runs persisted with a checkpointer can be inspected post-hoc via `hypergraph runs`.\n",
    "\n",
    "The flow: **run with a checkpointer → inspect with CLI**.\n",
    "\n",
    "First, create some runs to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, tempfile, os\n",
    "from hypergraph import AsyncRunner\n",
    "from hypergraph.checkpointers import SqliteCheckpointer\n",
    "\n",
    "# Temp DB for this demo (cleaned up when notebook restarts)\n",
    "_tmp = tempfile.mkdtemp()\n",
    "DB = os.path.join(_tmp, \"playground.db\")\n",
    "\n",
    "cp = SqliteCheckpointer(DB, durability=\"sync\")\n",
    "async_runner = AsyncRunner(checkpointer=cp)\n",
    "\n",
    "# A successful run\n",
    "await async_runner.run(graph, {\"x\": 5}, workflow_id=\"demo-pipeline\")\n",
    "\n",
    "# A cyclic workflow\n",
    "@ifelse(when_true=END, when_false=\"count_up\")\n",
    "def stop(count: int) -> bool:\n",
    "    return count >= 3\n",
    "\n",
    "@node(output_name=\"count\")\n",
    "def count_up(count: int) -> int:\n",
    "    return count + 1\n",
    "\n",
    "cycle_graph = Graph([count_up, stop])\n",
    "await async_runner.run(cycle_graph, {\"count\": 0}, workflow_id=\"demo-cycle\")\n",
    "\n",
    "# A partially failed run\n",
    "@node(output_name=\"ok\")\n",
    "def succeed(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "@node(output_name=\"boom\")\n",
    "def fail_node(x: int) -> int:\n",
    "    raise RuntimeError(\"intentional failure\")\n",
    "\n",
    "fail_graph = Graph([succeed, fail_node])\n",
    "await async_runner.run(fail_graph, {\"x\": 1}, workflow_id=\"demo-failure\", error_handling=\"continue\")\n",
    "\n",
    "print(f\"DB: {DB}\")\n",
    "print(f\"Runs created: {len(cp.runs())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### `runs` — Quick dashboard\n",
    "\n",
    "Shows active and recent runs at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hypergraph runs --db {DB}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### `runs ls` — List and filter\n",
    "\n",
    "Filter by status, graph name, or time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hypergraph runs ls --db {DB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hypergraph runs ls --status failed --db {DB}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### `runs show` — Inspect a single run\n",
    "\n",
    "Step-by-step execution trace. Use `--errors` to focus on failures, `--step N` to zoom in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hypergraph runs show demo-pipeline --db {DB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclic workflow — shows re-executions across supersteps\n",
    "!hypergraph runs show demo-cycle --db {DB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on errors only\n",
    "!hypergraph runs show demo-failure --errors --db {DB}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### `runs values` — Output values\n",
    "\n",
    "What did the run produce? Use `--key` to extract a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hypergraph runs values demo-pipeline --db {DB}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hypergraph runs values demo-pipeline --key tripled --db {DB}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### `runs steps` — Step-level detail\n",
    "\n",
    "Full step records with timing and values. Use `--values` to see outputs, `--node` to filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hypergraph runs steps demo-cycle --values --db {DB}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### `runs search` — Full-text search\n",
    "\n",
    "Search across node names and error messages using FTS5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hypergraph runs search \"failure\" --db {DB}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### `runs stats` — Performance profiling\n",
    "\n",
    "Per-node execution count, duration, and error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats shine for cyclic workflows — shows how many times each node ran\n",
    "!hypergraph runs stats demo-cycle --db {DB}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### JSON output — Machine-readable\n",
    "\n",
    "Every command supports `--json` for agent/script consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hypergraph runs show demo-pipeline --json --db {DB}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "## 8. Python API — Same queries, no CLI\n",
    "\n",
    "Every CLI command has a sync Python equivalent on `SqliteCheckpointer`. No `await` needed.\n",
    "\n",
    "| CLI | Python |\n",
    "|-----|--------|\n",
    "| `runs ls` | `cp.runs()` |\n",
    "| `runs ls --status failed` | `cp.runs(status=WorkflowStatus.FAILED)` |\n",
    "| `runs show <id>` | `cp.run(id)` + `cp.steps(id)` |\n",
    "| `runs values <id>` | `cp.values(id)` |\n",
    "| `runs values <id> --key x` | `cp.values(id, key=\"x\")` |\n",
    "| `runs steps <id>` | `cp.steps(id)` |\n",
    "| `runs search \"query\"` | `cp.search(\"query\")` |\n",
    "| `runs stats <id>` | `cp.stats(id)` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all runs\n",
    "cp.runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single run's metadata\n",
    "cp.run(\"demo-pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output values — what did the run produce?\n",
    "cp.values(\"demo-pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a single key\n",
    "cp.values(\"demo-pipeline\", key=\"tripled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step records — full execution trace\n",
    "cp.steps(\"demo-cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full-text search across all runs\n",
    "cp.search(\"failure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-node performance stats\n",
    "cp.stats(\"demo-cycle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint — snapshot for forking/retrying\n",
    "cp.checkpoint(\"demo-pipeline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
