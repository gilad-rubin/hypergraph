---
phase: 03-enforcement-and-errors
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/hypergraph/graph.py
  - tests/test_graph.py
autonomous: true

must_haves:
  truths:
    - "Graph with strict_types=True raises GraphConfigError for missing type annotations"
    - "Graph with strict_types=True raises GraphConfigError for type mismatches"
    - "Error message names the specific nodes and parameters involved"
    - "Error message includes How to fix guidance"
  artifacts:
    - path: "src/hypergraph/graph.py"
      provides: "_validate_types method integrated into _validate"
      contains: "_validate_types"
    - path: "tests/test_graph.py"
      provides: "Type validation error tests"
      contains: "test_strict_types"
  key_links:
    - from: "Graph._validate"
      to: "_validate_types"
      via: "method call when strict_types=True"
      pattern: "_validate_types"
    - from: "_validate_types"
      to: "_typing.is_type_compatible"
      via: "import and call"
      pattern: "is_type_compatible"
---

<objective>
Add type validation enforcement to Graph when strict_types=True.

Purpose: Catch type mismatches and missing annotations at graph construction time with helpful error messages following existing GraphConfigError patterns.

Output: Working type validation with clear error messages that identify problems and suggest fixes.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase summaries (this phase builds on them)
@.planning/phases/01-type-extraction-infrastructure/01-01-SUMMARY.md
@.planning/phases/02-type-compatibility-engine/02-01-SUMMARY.md

# Source files to modify/reference
@src/hypergraph/graph.py
@src/hypergraph/_typing.py
@src/hypergraph/nodes/function.py
@src/hypergraph/nodes/graph_node.py
@tests/test_graph.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add _validate_types method to Graph</name>
  <files>src/hypergraph/graph.py</files>
  <action>
Add type validation to Graph class:

1. Import from _typing at the top:
   ```python
   from hypergraph._typing import is_type_compatible, NoAnnotation
   ```

2. In `_validate()` method, add call to `_validate_types()` as last validation step (only if `self._strict_types` is True):
   ```python
   if self._strict_types:
       self._validate_types()
   ```

3. Add `_validate_types()` method that:
   - Iterates over all edges in the graph
   - For each edge (source_node -> target_node with value_name):
     - Get source node's output type for value_name using `output_annotation`
     - Get target node's input type for value_name using `parameter_annotations`
     - If EITHER type is missing (not in dict), raise GraphConfigError for missing annotation
     - If both exist, check compatibility with `is_type_compatible(output_type, input_type)`
     - If incompatible, raise GraphConfigError for type mismatch

4. Error message format for MISSING annotation (following existing convention):
   ```
   Missing type annotation in strict_types mode

     -> Node '{node_name}' {parameter|output} '{param_name}' has no type annotation

   How to fix:
     Add type annotation: def {node_name}({param_name}: YourType) -> ReturnType
   ```

5. Error message format for TYPE MISMATCH:
   ```
   Type mismatch between nodes

     -> Node '{source_name}' output '{value_name}' has type: {output_type}
     -> Node '{target_name}' input '{value_name}' expects type: {input_type}

   How to fix:
     Either change the type annotation on one of the nodes, or add a
     conversion node between them.
   ```

IMPORTANT:
- FunctionNode has `parameter_annotations` (dict[str, Any]) and `output_annotation` (dict[str, Any])
- GraphNode has `output_annotation` only (dict[str, Any])
- For multi-output nodes, output_annotation maps output_name -> type
- For single-output nodes, output_annotation maps output_name -> type (using the output's name, NOT "return")
- Missing annotation means the key doesn't exist in the dict (return empty dict {} on error)
- Only validate edges (connections), not unconnected inputs (those come from outside the graph)
  </action>
  <verify>
    - `uv run python -c "from hypergraph import Graph, node; from hypergraph._typing import is_type_compatible"`
    - `uv run python -c "from hypergraph.graph import Graph; print('_validate_types' in dir(Graph))"`  should print True
  </verify>
  <done>
    - _validate_types method exists on Graph
    - Method is called from _validate() when strict_types=True
    - Method checks both missing annotations and type mismatches
    - Error messages follow GraphConfigError format with "How to fix"
  </done>
</task>

<task type="auto">
  <name>Task 2: Add tests for type validation</name>
  <files>tests/test_graph.py</files>
  <action>
Add tests for type validation in tests/test_graph.py.

Create a new test class `TestStrictTypesValidation` with tests:

1. `test_strict_types_missing_input_annotation`:
   - Node with unannotated input parameter connected to annotated output
   - Should raise GraphConfigError mentioning missing annotation
   - Should mention the node name and parameter name
   - Should include "How to fix" guidance

2. `test_strict_types_missing_output_annotation`:
   - Node with annotated input connected to node with unannotated output
   - Should raise GraphConfigError for missing output annotation
   - Should mention which node and output lacks annotation

3. `test_strict_types_type_mismatch`:
   - Node outputs `int`, downstream node expects `str`
   - Should raise GraphConfigError for type mismatch
   - Should mention both node names, the value name, and both types

4. `test_strict_types_compatible_types_pass`:
   - Node outputs `int`, downstream expects `int`
   - Should NOT raise (valid graph)

5. `test_strict_types_union_compatible`:
   - Node outputs `int`, downstream expects `int | str`
   - Should NOT raise (int is compatible with int | str)

6. `test_strict_types_disabled_skips_validation`:
   - Node outputs `int`, downstream expects `str`, but strict_types=False
   - Should NOT raise (validation disabled)

7. `test_strict_types_graphnode_output`:
   - GraphNode's output connects to FunctionNode
   - Type validation should work using GraphNode.output_annotation
   - Test both compatible and incompatible cases

Test pattern example:
```python
def test_strict_types_type_mismatch(self):
    @node(output_name="result")
    def producer() -> int:
        return 42

    @node(output_name="final")
    def consumer(result: str) -> str:
        return result

    with pytest.raises(GraphConfigError) as exc_info:
        Graph([producer, consumer], strict_types=True)

    assert "Type mismatch" in str(exc_info.value)
    assert "producer" in str(exc_info.value)
    assert "consumer" in str(exc_info.value)
    assert "result" in str(exc_info.value)
    assert "How to fix" in str(exc_info.value)
```

IMPORTANT: Import `node` from hypergraph if not already imported in tests.
  </action>
  <verify>
    - `uv run pytest tests/test_graph.py -v -k "strict_types"` - all new tests pass
    - `uv run pytest tests/` - all existing tests still pass
  </verify>
  <done>
    - At least 7 tests for type validation
    - Tests cover missing annotations, type mismatches, compatible types
    - Tests verify error message content
    - Tests cover GraphNode type validation
    - All tests pass
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `uv run pytest tests/test_graph.py -v -k "strict_types"` passes
- [ ] `uv run pytest tests/` passes (all 200+ tests)
- [ ] Type mismatch raises GraphConfigError with both node names
- [ ] Missing annotation raises GraphConfigError with node/param name
- [ ] Error messages include "How to fix" guidance
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- No errors or warnings introduced
- TYPE-05 requirement satisfied: strict_types=True raises error for missing annotations
- TYPE-06 requirement satisfied: Error messages show which types conflict and how to fix
</success_criteria>

<output>
After completion, create `.planning/phases/03-enforcement-and-errors/03-01-SUMMARY.md`
</output>
